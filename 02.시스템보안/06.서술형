XXE(XML eXternal Entity) Injection>
[코드 1]
＜?xml version="1.0"?＞
＜!DOCTYPE foo
＜!ELEMENT foo ANY
＜!ENTITY xxe SYSTEM "file:///etc/passwd" ＞]＞
＜foo＞ &xxe ;＜/foo＞
[코드 2]
＜?xml version="1.0"?＞
＜!DOCTYPE lols
＜!ENTITY lol "lol"＞
＜!ENTITY lol2 "&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;"＞
＜!ENTITY lol3 "&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;"＞
..... ＜!ENTITY lol9 "&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;"＞
]＞
＜lols＞&lol9;＜/lols>
-XML 문서 내에서 외부의 개체를 참조하게 되는데 이때 외부 개체에 삽입된 악의적인 코드가 실행되어 데이터 유출, 서비스거부공격 등을 수행
-[코드2] 수행 시 엔티티 참조를 반복하면서 메모리고갈, 이로인한 서비스 불가

robots.txt
로봇배제표준(robots exclusion standard) : 로봇 배제 프로토콜은 웹사이트에 로봇이 접근하는 것을 방지하기 위한 규약. 일반적으로 접근제한에 대한 설명을 robots.txt에 기술한다.
웹사이트에 로봇에이전트(agent)가 접근하여 크롤링하는 것을 제한하기 위한 파일
User-agent: robots.txt 에서 지정하는 크롤링 규칙이 적용되어야 할 크롤러를 지정합니다.
Allow: 크롤링을 허용할 경로입니다 (/ 부터의 상대 경로).
Disallow: 크롤링을 제한할 경로입니다 (/ 부터의 상대 경로).
Sitemap: 사이트맵이 위치한 경로의 전체 URL입니다 (https:// 부터 /sitemap.xml 까지의 전체 절대경로 URL)
ex)
User-agent:*   모든 검색엔진에 대해
Disallow: /      모든 폴더 검색을 차단하고
Allow : /$       차단하지만 모든 폴더의 첫번째 페이지는 검색 허용
검색엔진로봇(crawler) 구글:Googlebot / 네이버:Yeti / Bing:Bingbot / Yahoo:Slurp
Google : https://www.google.co.kr/robots.txt     --robots.txt 파일은 웹서버 폴더 중 최상위 root 디렉터리(페이지)에 저장해야 함. 그래야 로봇이 확인가능. 
     *네이버 검색엔진로봇 특징 (Creator Rank알고리즘 & Deep Intent Analysis알고리즘)
      첫 번째는 언어처리 능력의 차이이다. 네이버의 경우 '개똥부스러기까먹헛소리쟁이'라는 복합명사이자 
     신조어인 검색어를 검색하면 아무 결과를 보여주지 않지만 구글은 복합명사를 분해하여 '개똥'이라는 
     단어가 있는 문서도 보여주고 접미사 '쟁이'도 이해하여 관련 단어가 있는 문서를 보여준다.
      두 번째 차이는 검색 결과의 폐쇄성이다. 구글, 야후 등의 검색엔진이 외부 문서를 검색 결과에 적극적으로
     노출하고 자사 플랫폼에 올라온 콘텐츠와 검색결과에 차별을 두지 않는 데 반해 네이버는 네이버 블로그나
     네이버 카페에 올라오는 자사 플랫폼의 콘텐츠 위주로 검색 결과를 노출하는 경향이 있다. 최근에는 네이버도 
     외부 사이트의 콘텐츠를 적극적으로 수집하려는 경향을 보이고 있다.
      세 번째는 콘텐츠 분류 차이다. 네이버의 경우 콘텐츠가 올라온 플랫폼에 따라 콘텐츠를 영역별로 구분하여 보여준다.
     네이버 통합 검색 결과는 네이버 블로그와 네이버 카페에 올라온 콘텐츠를 보여주는 'VIEW 영역'과 질문과 답변으로 
     구성되는 '지식iN 영역', '뉴스 영역' 등으로 분류된다. 반면 구글은 전체 검색 결과에서 콘텐츠 별로 보여지는 영역을
     나누지 않고 모든 콘텐츠를 한 페이지에 보여준다.
      네 번째는 중복 콘텐츠를 방지하는 정도의 차이다. 네이버 검색엔진은 어떤 글이 원문이고, 어떤 글이 복사 글인지 파악하지
     못하여 무단으로 복사한 글이 원본 글보다 상위에 노출되는 경우가 있다. 네이버는 동일한 콘텐츠를 배포할 때 원래 글을
     검색엔진이 알 수 있도록 하는 캐노니컬 태그를 입력하는 방법을 자사 플랫폼에서 제공하지 않는다.
      마지막으로 광고 노출 섹션 크기에 차이가 있다. 네이버의 경우 파워링크 영역이 통합 검색 결과의 최상위에 위치하여 넓은 영역을 차지하는 
     면, 구글의 경우 광고 영역이 전체 검색 결과에서 많은 영역을 차지하지 않는다.

백도어가 설치되어 있는 것을 아래 보기와 같이 확인하였으나, 해당 파일 경로로 가보니 파일이 존재하지 않았다. 
$ ls -al /proc/5900
1) 백도어 파일 경로로 접속시 해당 프로세스가 보이지 않는 이유는? 공격자가 백도어프로세스 실행 후 해당파일을 삭제했기 때문
2) 삭제된 백도어 프로세스를 /tmp/backdoor로 복원하는 명령어는? cp /proc/5900/exe /tmp/backdoor
3) 공격자가 사용한 명령어를 확인하는 방법은 무엇인가?(단, ps는 변조되어 사용 불가함) history(명령어 뒤 입력한 parameter까지 확인) || cat /proc/5900/cmdline

Slow HTTP Post DOS(RUDY)
POST Request에 대하여 컨텐츠 길이(Content-Length)가 10000000이라는 큰 값으로 설정되어 있는데 패킷 캡처 화면을 보면
작은 양의 데이터를 조금씩 분할 전송하고 있음. 이는 POST방식이 데이터를 다 받을때까지 기다리는다는 점을 이용,
서버가 10000000byte의 데이터가 모두 도착할 때까지 연결을 장시간 유지하여 서버의 가용량을 소진하게하고 다른 클라이언트로
부터의 정상적인 서비스 요청을 처리하지 못하도록 하는 공격
대응방안) 
연결타임아웃설정(Connection Timeout) : 클라이언트와 서버간 일정 연결유지시간 초과시 자동 연결종료
읽기타임아웃설정(Read Timeout) : 지정된 시간내에 body정보가 모두 수신되지 않으면 오류코드 반환
서버방화벽설정 : iptables와 같은 방화벽을 통해 동일한 소스 IP에서 동시연결가능한 개수의 임계치를 설정하여 초과시 차단
   *iptables(리눅스) : 패킷필터링도구로서 방화벽이나 NAT(Network Address Translation)에 사용

정적분석vs동적분석
정적분석 : 프로그램의 기능을 파악하고 코드나 프로그램의 구조를 분석하는 단계로 실제로 실행해보지 않고 분석하는 것
동적분석 : 직접 실행하여 실행된 결과를 직접 관찰하여 분석하는 것으로, 분석이 용이하지만 안전한 샌드박스환경(가상화PC)에서 수행되어야 함
   동적분석 방해 : 분석되는 것을 방지하기 위해 특정조건 하에서만 동작하도록 하는 기법
             -에뮬레이터, 루팅된 폰에서 동작안함
             -침해가 가능한 기종에서만 동작함
             -침해대상 정보가 있는 환경에서만 동작
