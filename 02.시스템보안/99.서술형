쿠키(Cookie)
사용자가 웹서버에 접속하여 로그인하면 생성되는 정보를 사용자의 컴퓨터에 저장해 놓았다가 다음에 다시 접속했을 때는 별도의 로그인 절차 없이 사이트에 빠르게 접속할 수 있게 함
개별 클라이언트 상태정보를 HTTP 요청/응답 헤더에 담아서 전달하는 작은 정보 또는 데이터를 의미함
Set-Cookie: ID=KISA; Path=/; secure
-쿠키에 Secure속성을 설정할 경우 클라이언트(웹브라우저 등)에서 HTTPS통신(암호화통신)일 경우에만 해당 쿠키를 전송하고 HTTP통신(평문통신)일 경우에는
 전송하지 않도록 하여 쿠키정보의 기밀성을 보장할 수 있음. 이를 통해 Network Sniffing을 통해 평문 쿠키 정보를 탈취하는 형태의 공격에 대응가능
Set-Cookie: ID=KISA; Path=/; HttpOnly
-쿠키에 HttpOnly속성을 설정할 경우 클라이언트(웹브라우저 등)에서 스크립트(자바스크립트 등)을 통한 쿠키 접근을 차단하여 악의적인 쿠키정보 탈취를 방지

XXE(XML eXternal Entity) Injection>
[코드 1]
＜?xml version="1.0"?＞
＜!DOCTYPE foo
＜!ELEMENT foo ANY
＜!ENTITY xxe SYSTEM "file:///etc/passwd" ＞]＞
＜foo＞ &xxe ;＜/foo＞
[코드 2]
＜?xml version="1.0"?＞
＜!DOCTYPE lols
＜!ENTITY lol "lol"＞
＜!ENTITY lol2 "&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;"＞
＜!ENTITY lol3 "&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;"＞
..... ＜!ENTITY lol9 "&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;"＞
]＞
＜lols＞&lol9;＜/lols>
-XML 문서 내에서 외부의 개체를 참조하게 되는데 이때 외부 개체에 삽입된 악의적인 코드가 실행되어 데이터 유출, 서비스거부공격 등을 수행
-[코드2] 수행 시 엔티티 참조를 반복하면서 메모리고갈, 이로인한 서비스 불가

robots.txt
로봇배제표준(robots exclusion standard) : 로봇 배제 프로토콜은 웹사이트에 로봇이 접근하는 것을 방지하기 위한 규약. 일반적으로 접근제한에 대한 설명을 robots.txt에 기술한다.
웹사이트에 로봇에이전트(agent)가 접근하여 크롤링하는 것을 제한하기 위한 파일
User-agent: robots.txt 에서 지정하는 크롤링 규칙이 적용되어야 할 크롤러를 지정합니다.
Allow: 크롤링을 허용할 경로입니다 (/ 부터의 상대 경로).
Disallow: 크롤링을 제한할 경로입니다 (/ 부터의 상대 경로).
Sitemap: 사이트맵이 위치한 경로의 전체 URL입니다 (https:// 부터 /sitemap.xml 까지의 전체 절대경로 URL)
ex)
User-agent:*   모든 검색엔진에 대해
Disallow: /      모든 폴더 검색을 차단하고
Allow : /$       차단하지만 모든 폴더의 첫번째 페이지는 검색 허용
검색엔진로봇(crawler) 구글:Googlebot / 네이버:Yeti / Bing:Bingbot / Yahoo:Slurp
Google : https://www.google.co.kr/robots.txt     --robots.txt 파일은 웹서버 폴더 중 최상위 root 디렉터리(페이지)에 저장해야 함. 그래야 로봇이 확인가능. 
     *네이버 검색엔진로봇 특징 (Creator Rank알고리즘 & Deep Intent Analysis알고리즘)
      첫 번째는 언어처리 능력의 차이이다. 네이버의 경우 '개똥부스러기까먹헛소리쟁이'라는 복합명사이자 
     신조어인 검색어를 검색하면 아무 결과를 보여주지 않지만 구글은 복합명사를 분해하여 '개똥'이라는 
     단어가 있는 문서도 보여주고 접미사 '쟁이'도 이해하여 관련 단어가 있는 문서를 보여준다.
      두 번째 차이는 검색 결과의 폐쇄성이다. 구글, 야후 등의 검색엔진이 외부 문서를 검색 결과에 적극적으로
     노출하고 자사 플랫폼에 올라온 콘텐츠와 검색결과에 차별을 두지 않는 데 반해 네이버는 네이버 블로그나
     네이버 카페에 올라오는 자사 플랫폼의 콘텐츠 위주로 검색 결과를 노출하는 경향이 있다. 최근에는 네이버도 
     외부 사이트의 콘텐츠를 적극적으로 수집하려는 경향을 보이고 있다.
      세 번째는 콘텐츠 분류 차이다. 네이버의 경우 콘텐츠가 올라온 플랫폼에 따라 콘텐츠를 영역별로 구분하여 보여준다.
     네이버 통합 검색 결과는 네이버 블로그와 네이버 카페에 올라온 콘텐츠를 보여주는 'VIEW 영역'과 질문과 답변으로 
     구성되는 '지식iN 영역', '뉴스 영역' 등으로 분류된다. 반면 구글은 전체 검색 결과에서 콘텐츠 별로 보여지는 영역을
     나누지 않고 모든 콘텐츠를 한 페이지에 보여준다.
      네 번째는 중복 콘텐츠를 방지하는 정도의 차이다. 네이버 검색엔진은 어떤 글이 원문이고, 어떤 글이 복사 글인지 파악하지
     못하여 무단으로 복사한 글이 원본 글보다 상위에 노출되는 경우가 있다. 네이버는 동일한 콘텐츠를 배포할 때 원래 글을
     검색엔진이 알 수 있도록 하는 캐노니컬 태그를 입력하는 방법을 자사 플랫폼에서 제공하지 않는다.
      마지막으로 광고 노출 섹션 크기에 차이가 있다. 네이버의 경우 파워링크 영역이 통합 검색 결과의 최상위에 위치하여 넓은 영역을 차지하는 
     면, 구글의 경우 광고 영역이 전체 검색 결과에서 많은 영역을 차지하지 않는다.

백도어가 설치되어 있는 것을 아래 보기와 같이 확인하였으나, 해당 파일 경로로 가보니 파일이 존재하지 않았다. 
$ ls -al /proc/5900
1) 백도어 파일 경로로 접속시 해당 프로세스가 보이지 않는 이유는? 공격자가 백도어프로세스 실행 후 해당파일을 삭제했기 때문
2) 삭제된 백도어 프로세스를 /tmp/backdoor로 복원하는 명령어는? cp /proc/5900/exe /tmp/backdoor
3) 공격자가 사용한 명령어를 확인하는 방법은 무엇인가?(단, ps는 변조되어 사용 불가함) history(명령어 뒤 입력한 parameter까지 확인) || cat /proc/5900/cmdline

Slow HTTP Post DOS(RUDY)
POST Request에 대하여 컨텐츠 길이(Content-Length)가 10000000이라는 큰 값으로 설정되어 있는데 패킷 캡처 화면을 보면
작은 양의 데이터를 조금씩 분할 전송하고 있음. 이는 POST방식이 데이터를 다 받을때까지 기다리는다는 점을 이용,
서버가 10000000byte의 데이터가 모두 도착할 때까지 연결을 장시간 유지하여 서버의 가용량을 소진하게하고 다른 클라이언트로
부터의 정상적인 서비스 요청을 처리하지 못하도록 하는 공격
대응방안) 
연결타임아웃설정(Connection Timeout) : 클라이언트와 서버간 일정 연결유지시간 초과시 자동 연결종료
읽기타임아웃설정(Read Timeout) : 지정된 시간내에 body정보가 모두 수신되지 않으면 오류코드 반환
서버방화벽설정 : iptables와 같은 방화벽을 통해 동일한 소스 IP에서 동시연결가능한 개수의 임계치를 설정하여 초과시 차단
   *iptables(리눅스) : 패킷필터링도구로서 방화벽이나 NAT(Network Address Translation)에 사용

정적분석vs동적분석
정적분석 : 프로그램의 기능을 파악하고 코드나 프로그램의 구조를 분석하는 단계로 실제로 실행해보지 않고 분석하는 것
동적분석 : 직접 실행하여 실행된 결과를 직접 관찰하여 분석하는 것으로, 분석이 용이하지만 안전한 샌드박스환경(가상화PC)에서 수행되어야 함
   동적분석 방해 : 분석되는 것을 방지하기 위해 특정조건 하에서만 동작하도록 하는 기법
             -에뮬레이터, 루팅된 폰에서 동작안함
             -침해가 가능한 기종에서만 동작함
             -침해대상 정보가 있는 환경에서만 동작


백업용 쉘 스크립트 파일과 백업 결과 파일
[백업용 쉘 스크립트 파일(backup.sh)]
#!/bin/sh
today = $(date +%Y%m%d%H%M%S)
tar -cvzf /data/backup/etc_$dat.tgz /etc/*
tar -cvzf /data/backup/home_$dat.tgz /home/*
[백업 결과 파일 목록]
ㅡrwㅡrㅡㅡrㅡㅡ1 root root 101853308 2021-03-10 13:39 etc_202103101339.tgz
ㅡrwㅡrㅡㅡrㅡㅡ1 root root 40736 2021-03-10 13:39 home_202103101339.tgz
보안상 문제 : 백업파일 접근권한이 644로 생성되어 일반 사용자가 생성된 백업 파일에 접근하여 읽을 수 있는 문제가 있다
개선사항 : tar 명령이전(백업 파일을 생성하기 전)에 umask 066 설정 후 tar 명령이 끝난 후 umask 022로 원복
operater사용자만 백업용 쉘 스크립트파일(/usr/local/bin/backup.sh)을 사용하도록 만드는 명령어 :
 $chown operator /usr/local/bin/backup.sh  --쉘스크립트 파일의 소유자를 operator로 변경
 $chmod 700 /usr/local/bin/backup.sh       --쉘스크립트 파일의 접근권한을 소유자만 접근가능하도록 700으로 변경

DNS Amplification Attack
[로그]
DNS standard query 0x2872 ANY cpsc.gov United states Korea, Republic of
DNS standard query 0x2872 ANY cpsc.gov United states Korea, Republic of
DNS standard query 0x2872 ANY cpsc.gov United states Korea, Republic of
DNS standard query 0x2872 ANY cpsc.gov United states Korea, Republic of
DNS Amplification Attack(DNS 증폭 반사 디도스 공격)
판단이유 : DNS 질의(Query) 수행 시 ANY 타입으로 질의를 다수 수행/TXT타입의 response를 다량 수행
원리 : 출발지IP를 공격대상서버의 IP로 위조 후(IP spoofing) DNS쿼리타입을 ANY(=all)로 지정하여 request를 대량 수행하면,
      다양한 TYPE의 레코드들이 모두 Response 되므로 응답이 증폭되어 공격 대상 서버에 부하를 주게됨
      *ANY : 하나의 응답으로 IPv4,IPv6,메일서버주소,네임서버주소. 즉 하나의 요구로 여러개의 응답을 요구. 90byte질의/3370byte응답--약 37.4배 증폭)
사용목적 :
출발지IP위조되고 반사서버를 통해 공격이 수행(DRDoS)되므로 공격의 출처를 파악하기 어려움
UDP프로토콜의 신속성, 대량성. UDP는 별도의 인증절차가 없으므로 공격 수행이 용이
쿼리타입을 any나 txt로 하여 response size 증폭. 다수의 좀비PC를 동원하지 않더라도 대량의 공격패킷을 만들어 낼 수 있어 효율이 높음
공격단계 :
1.공격자는 손상된 Endpoint를 사용하여 UDP패킷과 스푸핑된IP주소와 DNS재귀자에게 전송한다. 패킷에 포함된 스푸핑된 주소는 victim의 실제 IP주소
2.모든 UDP패킷이 각각 DNS확인자에 요청을하며, 대개는 "ANY" 인수를 전달하여 가능한 한 가장 큰 응답을 수신
3.DNS확인자는 요청을 수신하면, 응답을 통해 도움을 주고자하므로 스푸핑된IP주소로 많은 양의 응답을 보냄
4.목표 victim의 IP주소는 이 응답을 수신하게 되고 주변 네트워크 인프라가 이러한 트래픽의 폭주로 인해 압도되어 서비스거부가 발생

php(Server side script)
system(), exec() 같은 운영체제의 명령어를 실행 할 수 있는 함수가 실행되는 페이지를 include 한 경우 명령어 삽입을 통한 공격이 가능하다. 
이러한 취약점을 방지하기 위해서
코드에 (A:include/require) 문이 존재하는 검증 하고
PHP의 경우 외부 사이트의 파일을 삽입 차단하기 위해 설정 파일인 (B:php.ini)의
allow_url_fopen=(C:off)로 변경한다.
-PHP의 경우 include나 require함수를 이용하여 외부파일을 본문에 포함시킬 수 있다
-이렇게 include되는 파일 내부에 system()처럼 운영체제 명령어 실행이 가능한 함수 메소드가 있을경우
 원격으로 OS명령어를 수행할 수 있고, 대부분의 WebShell은 이런 기능을 포함하고 있다
-PHP파일과 동일한 로컬 서버에 있는 파일을 include시키는 공격은 LFI(Local File Inclusion)라 하고
 외부의 파일을 include시키는 경우 RFI(Remote File Inclusion)이라고 한다
-이런 파일 포함 공격을 방지하기 위해서는 PHP 환경설정 파일인 php.ini에서 Safe_mode = On하여
 shell_exe(), system() 함수 등을 제한하거나, allow_url_fopen이나 allow_url_include를 off로 설정하여
 외부 파일을 php본문에 include하지 못하도록 설정한다.

파일업로드취약점 : 파일첨부가 가능한 게시판 등 웹 환경에서 실행 가능한 악의적인 스크립트(jsp,php,sh 등) 파일을 업로드하여 서버에서 실행
                 클라이언트에서 서버 측으로 임의의 파일을 보낼 수 있는 취약점은 웹서버가 가질 수 있는 가장 치명적인 취약점
                 가장 일반적인 형태는 게시판이고 악의적인 파일을 업로드 후 실행. 이 때 업로드하는 악성코드는 대부분 "웹쉘"임
대응방안 : 확장자나 파일헤더를 통해 이미지,문서 등 정해진 파일만 올릴 수 있도록 파일이 저장되는 디렉터리의 실행권한을 없앰
          악성 파일 업로드방지를 위해 업로드 파일에 대한 확장자 필터링을 통해 제한
          외부에 Open된 회사 홈페이지는 외부Network와 내부Network 사이에 위치한 DMZ구간에 구축하는 것이 좋음

로그파일 : 컴퓨터 시스템의 모든 사용내역을 기록하고 있는 파일
 침입자로부터 로그파일을 보호하는 법 : 백업, 암호화 등 지속적인 관리를 주기적으로 해야 함

